# Imports
import pandas as pd
import numpy as np
import os
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import __version__ as sklearn_version
from sklearn.decomposition import PCA
from sklearn.preprocessing import scale, StandardScaler
from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.dummy import DummyRegressor
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.pipeline import make_pipeline
import datetime

# Save function
def save_file(data, filename, datapath):
    filepath = os.path.join(datapath, filename)
    with open(filepath, 'wb') as file:
        pickle.dump(data, file)

# Load Data
data_path = r'C:\Users\jwhit\OneDrive\Documents\Data Science Course\Cap2 Project\Processed_Data\Merged_Wrangle_Data(EDA).csv'
data = pd.read_csv(data_path)

# Display basic information and a preview of the data
data.info()
print(data.head())

# Split the data into train and test sets
X = data.drop(columns=['Revenue'])  # Replace 'Revenue' with the target column
y = data['Revenue']  # Target column
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Identify non-numeric columns
non_numeric_cols = X_train.select_dtypes(include=['object']).columns
print("Non-numeric columns:", non_numeric_cols)

# Drop non-numeric columns or encode them if necessary
X_tr_numeric = X_train.drop(columns=non_numeric_cols)
X_te_numeric = X_test.drop(columns=non_numeric_cols)

# Handle NaN values in target variables
y_train = y_train.fillna(y_train.median())
y_test = y_test.fillna(y_test.median())

# Scale the data
scaler = StandardScaler()
scaler.fit(X_tr_numeric)
X_tr_scaled = scaler.transform(X_tr_numeric)
X_te_scaled = scaler.transform(X_te_numeric)

# Initial Not-Even-A-Model: Dummy Regressor
dumb_reg = DummyRegressor(strategy='mean')
dumb_reg.fit(X_tr_scaled, y_train)

# Make predictions using the dummy regressor
y_tr_pred = dumb_reg.predict(X_tr_scaled)
y_te_pred = dumb_reg.predict(X_te_scaled)

# Metrics Calculation
def r_squared(y, ypred):
    """R-squared score."""
    ybar = np.sum(y) / len(y)  # mean of y
    sum_sq_tot = np.sum((y - ybar)**2)  # total sum of squares error
    sum_sq_res = np.sum((y - ypred)**2)  # residual sum of squares error
    R2 = 1.0 - sum_sq_res / sum_sq_tot
    return R2

def mae(y, ypred):
    """Mean absolute error."""
    abs_error = np.abs(y - ypred)
    mae = np.mean(abs_error)
    return mae

def mse(y, ypred):
    """Mean square error."""
    sq_error = (y - ypred)**2
    mse = np.mean(sq_error)
    return mse

# Calculate R-squared, MAE, and MSE for training and test data
print("R-squared (train):", r_squared(y_train, y_tr_pred))
print("R-squared (test):", r_squared(y_test, y_te_pred))
print("Mean Absolute Error (train):", mae(y_train, y_tr_pred))
print("Mean Absolute Error (test):", mae(y_test, y_te_pred))
print("Mean Squared Error (train):", mse(y_train, y_tr_pred))
print("Mean Squared Error (test):", mse(y_test, y_te_pred))

# Linear Regression Model
lm = LinearRegression().fit(X_tr_scaled, y_train)

# Make predictions using the linear model
y_tr_pred = lm.predict(X_tr_scaled)
y_te_pred = lm.predict(X_te_scaled)

# Assess model performance
print("Linear Regression - R-squared (train):", r2_score(y_train, y_tr_pred))
print("Linear Regression - R-squared (test):", r2_score(y_test, y_te_pred))
print("Linear Regression - Mean Absolute Error (train):", mean_absolute_error(y_train, y_tr_pred))
print("Linear Regression - Mean Absolute Error (test):", mean_absolute_error(y_test, y_te_pred))
print("Linear Regression - Mean Squared Error (train):", mean_squared_error(y_train, y_tr_pred))
print("Linear Regression - Mean Squared Error (test):", mean_squared_error(y_test, y_te_pred))

# Pipeline Mean CV Score Visualization
pipe = make_pipeline(
    SimpleImputer(strategy='median'), 
    StandardScaler(),
    SelectKBest(f_regression),
    LinearRegression()
)

k = [k+1 for k in range(len(X_train.columns))]
grid_params = {'selectkbest__k': k}

grid_cv = GridSearchCV(pipe, param_grid=grid_params, cv=5, n_jobs=-1)
grid_cv.fit(X_tr_numeric, y_train)

score_mean = grid_cv.cv_results_['mean_test_score']
score_std = grid_cv.cv_results_['std_test_score']
cv_k = [k for k in grid_cv.cv_results_['param_selectkbest__k']]

best_k = grid_cv.best_params_['selectkbest__k']

plt.figure(figsize=(10, 6))
plt.errorbar(cv_k, score_mean, yerr=score_std, fmt='-o')
plt.axvline(x=best_k, color='r', linestyle='--', alpha=0.7, label=f'Best k = {best_k}')
plt.xlabel('Number of Selected Features (k)')
plt.ylabel('Mean CV Score (R-squared)')
plt.title('Pipeline Mean CV Score with Error Bars')
plt.legend()
plt.grid(True)
plt.show()

# Random Forest Model
RF_pipe = make_pipeline(
    SimpleImputer(strategy='median'),
    StandardScaler(),
    RandomForestRegressor(random_state=47)
)

# Fit and assess performance using cross-validation
rf_default_cv_results = cross_validate(RF_pipe, X_tr_numeric, y_train, cv=5)
rf_cv_scores = rf_default_cv_results['test_score']
print("Random Forest CV Scores:", rf_cv_scores)
print("Mean CV Score:", np.mean(rf_cv_scores))
print("Std CV Score:", np.std(rf_cv_scores))

# Best Random Forest Regressor Feature Importances
rf_grid_params = {
    'randomforestregressor__n_estimators': [50, 100, 200],
    'randomforestregressor__max_features': ['auto', 'sqrt', 'log2']
}

rf_grid_cv = GridSearchCV(RF_pipe, param_grid=rf_grid_params, cv=5, n_jobs=-1)
rf_grid_cv.fit(X_tr_numeric, y_train)

# Check if 'selectkbest' is in the pipeline steps
if 'selectkbest' in rf_grid_cv.best_estimator_.named_steps:
    # Extract the selected feature names
    selected_features = rf_grid_cv.best_estimator_.named_steps['selectkbest'].get_support(indices=True)
    features = X_tr_numeric.columns[selected_features]
else:
    # Use all features if 'selectkbest' is not present
    features = X_tr_numeric.columns

# Extract the feature importances from the random forest model
feature_importances = rf_grid_cv.best_estimator_.named_steps['randomforestregressor'].feature_importances_

# Create a DataFrame for feature importances
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=importance_df)
plt.title('Random Forest Feature Importances')
plt.show()

# Cross-Validation Score as Training Set Size Increases
fractions = [.2, .25, .3, .35, .4, .45, .5, .6, .75, .8, 1.0]
train_sizes, train_scores, test_scores = learning_curve(pipe, X_tr_numeric, y_train, train_sizes=fractions, cv=5)

train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores_mean, 'o-', label='Training Score')
plt.plot(train_sizes, test_scores_mean, 'o-', label='Cross-Validation Score')
plt.fill_between(train_sizes, 
                 train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.1, color="r")
plt.fill_between(train_sizes, 
                 test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.1, color="g")
plt.xlabel('Training Set Size')
plt.ylabel('Score')
plt.title('Learning Curve')
plt.legend(loc='best')
plt.grid(True)
plt.show()

# Save Best Model Object
best_model = RF_pipe
best_model.version = '1.0'
best_model.pandas_version = pd.__version__
best_model.numpy_version = np.__version__
best_model.sklearn_version = sklearn_version
best_model.X_columns = [col for col in X_tr_numeric.columns]
best_model.build_datetime = datetime.datetime.now()

# Save the model
modelpath = 'C:/Users/jwhit/OneDrive/Documents/Data Science Course/Cap2 Project/models'
if not os.path.exists(modelpath):
    os.makedirs(modelpath)

with open(os.path.join(modelpath, 'cap2_pricing_model.pkl'), 'wb') as file:
    pickle.dump(best_model, file)

print("Model saved successfully.")
